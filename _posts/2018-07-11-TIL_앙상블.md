---
layout: post
title:  "TIL: 앙상블 기법"
author: "LSM"
---

## 앙상블 기법
- 주어진 자료로부터 여러 개의 예측 모형을 만든 후 조합해 하나의 최종 예측 모형을 만드는 방법
- 학습 방법의 불안정성을 해결하기 위해 고안된 기법

### 1. 배깅
- 여러 개의 부트스트랩 자료를 생성 (자료를 랜덤하게 추출) 
- 새성 자료의 예측 모형 결과를 겹합해 결과를 선정
- 배깅을 통해 분산을 줄이고 예측력을 향상

### 2. 부스팅
- 예측력이 약한 모형들을 결합해 강한 예측 모형 생성
- 훈련 오차를 빠르고 쉽게 줄일 수 있음
- 예측 오차 향상으로 배깅에 비해 뛰어난 예측력을 보임

### 랜덤포레스트
- 일반적인 decision tree는 분산ㄴ이 큼
- 많은 무작위성을 주어 약한 학습기들을 생성 후 이를 선형 결합해 최종 학습기를 만듦
- 이론적 설명/해석이 어렵다는 단점이 존재
- 예측력이 매우 높음
- 입력 변수가 많을 수록 좋은 예측력을 가짐

### 스태킹
- 동일한 타입의 모델을 조합하는 배깅, 부스팅과 달리 다양한 학습 모델을 통해 구성