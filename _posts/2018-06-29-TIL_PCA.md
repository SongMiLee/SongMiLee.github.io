---
layout: post
title:  "TIL:PCA, eigenvalue, eigenvector"
author: "LSM"
---
# PCA
분산을 최대한 보존한 채 서로 직교하는 새 축을 찾아 고차원 데이터들을 저차원 공간으로 변형하는 기법

* 이미지와 같은 고차원 데이터에서 패턴을 찾는 알고리즘
* 데이터의 범위를 재조정
* 평균을 0으로 맞춰줌
* 고차원 데이터 중 중요한 차원을 골라줌
* **신경망 학습의 수렴속도와 성능을 향상시킬 수 있음**


### 변수 추출
기존 변수를 조합해 새로운 변수를 만드는 기법
**기존 변수를 선형 결합하여 새로운 변수를 만들어 냄**

### 고유값(eigenvalue) & 고유 벡터(eigenvector)
행렬 A를 선형 변환으로 봤을 때 선형 변환 A에 의한 변환 결과가 자기 자신의 상수배가 되는 0이 아닌 벡터를 eigenvector라 하며 상수배 값을 eigenvalue라 함

$$
Av = bv
$$

v는 고유 벡터
- 고유벡터는 행렬이 백터에 작용하는 힘의 방향
- 행렬 = 공분산, 고유벡터는 데이터의 분산 방향 및 어떻게 힘이 작용하는지를 나타냄

b는 고유벡터에 대한 상관 계수


** PCA에서는 고유값이 큰 순서 대로 고유벡터를 정렬 ==> 중요한 순서대로의 주성분 구하기**
